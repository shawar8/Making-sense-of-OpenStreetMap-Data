{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import cerberus\n",
    "import schema\n",
    "import csv\n",
    "import codecs\n",
    "import sqlite3\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the file we'll be using for our wrangling. I chose the city of L.A as it was a city I grew attached to during my Masters Program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_PATH = \"C:\\Users\\shawar\\Documents\\la_map.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function below to show us the different types of tag attributes in the way and node tags and their count and present them as a dictionary. The function also allows us to check the different values for each tag key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def number_types(tag):\n",
    "    num_dict = defaultdict(int)\n",
    "    types_dict = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(OSM_PATH, events = ('start',)):\n",
    "        if elem.tag == 'way':\n",
    "            for tags in elem.iter(tag):\n",
    "                num_dict[tags.get('k')] += 1\n",
    "                types_dict[tags.get('k')].add(tags.get('v'))\n",
    "    return num_dict, types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caltrans:type 1\n",
      "tiger:source 2040\n",
      "maxspeed 627\n",
      "source_ref:oneway 3\n",
      "housing_type 1\n",
      "source:private 2\n",
      "turn:lanes:forward 322\n",
      "placement:forward 2\n",
      "is_in 23\n",
      "building:height 1\n",
      "maxspeed:truck 2\n",
      "tiger:AWATER 4\n",
      "created_by 235\n",
      "hov:minimum 4\n",
      "name:full 2\n",
      "attribution 34\n",
      "tiger:county 4761\n",
      "name:uk 1\n",
      "motor_vehicle 33\n",
      "faa 1\n",
      "railway:track_ref 3\n",
      "source_ref:bicycle 14\n",
      "addr:street 394\n",
      "source:name 17\n",
      "level 15\n",
      "cutline 5\n"
     ]
    }
   ],
   "source": [
    "num_types, types_values = number_types('tag')\n",
    "count = 0\n",
    "for key, value in num_types.items():\n",
    "    print key, value \n",
    "    if count == 25:\n",
    "        break    \n",
    "    count += 1                                          #small sample of different keys and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I first noticed was odd in the data was that there were many tags with the name 'FIXME'.\n",
    "\n",
    "We also see the many ways in which the same kind of data has different ways of describing them. For example, to describe the county in which the particular location is, we have - ('addr:county', 'is_in:county', 'gnis:county_name')\n",
    "\n",
    "I decided to look at important keys in the above dictionary a little more closely. (name, addr types, amenities, zipcodes, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 'fixme', 'v': 'split this intersection up'}\n",
      "{'k': 'fixme', 'v': \"what's here now? Lot is bulldozed on Bing\"}\n",
      "{'k': 'fixme', 'v': 'Location'}\n",
      "{'k': 'fixme', 'v': 'continue'}\n",
      "{'k': 'fixme', 'v': 'add height, ref pole number'}\n",
      "{'k': 'fixme', 'v': 'is this the right location?'}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for event, elem in ET.iterparse(OSM_PATH, events= ('start',)):\n",
    "    if count == 6:\n",
    "        break\n",
    "    else:\n",
    "        if elem.tag == 'node' or elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if tag.get('k') == 'fixme':\n",
    "                    count += 1\n",
    "                    print tag.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'caltrans:type'\n",
      "set(['HMS,LSMS'])\n",
      "'tiger:source'\n",
      "set(['TIGER 2011 ogr2osm import',\n",
      "     'tiger_import_dch_v0.6_20070809',\n",
      "     'tiger_import_jan_v0.5_20120613'])\n",
      "'maxspeed'\n",
      "set(['10 mph',\n",
      "     '112',\n",
      "     '127',\n",
      "     '14 mph',\n",
      "     '15 mph',\n",
      "     '20',\n",
      "     '20 mph',\n",
      "     '25',\n",
      "     '25 mph',\n",
      "     '30 mph',\n",
      "     '35 mph',\n",
      "     '37',\n",
      "     '38',\n",
      "     '40',\n",
      "     '40 mph',\n",
      "     '45',\n",
      "     '45 mph',\n",
      "     '48',\n",
      "     '5 mph',\n",
      "     '50',\n",
      "     '50 mph',\n",
      "     '55 mph',\n",
      "     '56',\n",
      "     '60 mph',\n",
      "     '65 mph',\n",
      "     '70 mph',\n",
      "     '96.5'])\n",
      "'source_ref:oneway'\n",
      "set(['AM909_DSCU2397', 'AM909_DSCU4562', 'AM909_DSCU4766'])\n",
      "'housing_type'\n",
      "set(['condominium'])\n",
      "'source:private'\n",
      "set(['LA County LA County Street Centerline & Address File (http://egis3.lacounty.gov/dataportal/2011/12/09/2011-la-county-street-centerline-street-address-file/)',\n",
      "     'survey;image;LACA;LACDPW'])\n",
      "'turn:lanes:forward'\n",
      "set(['left;through|',\n",
      "     'left;through|right|right',\n",
      "     'left;through||',\n",
      "     'left|',\n",
      "     'left|left;through',\n",
      "     'left|left;through|right',\n",
      "     'left|left|right',\n",
      "     'left|left|through|right',\n",
      "     'left|left||',\n",
      "     'left|left|||',\n",
      "     'left|left|||right',\n",
      "     'left|left||||right',\n",
      "     'left|none',\n",
      "     'left|none|',\n",
      "     'left|none|none',\n",
      "     'left|none|none|none',\n",
      "     'left|none|none|right',\n",
      "     'left|none|right',\n",
      "     'left|right',\n",
      "     'left|right|right',\n",
      "     'left|through|right',\n",
      "     'left|through|through',\n",
      "     'left|through|through;right',\n",
      "     'left||',\n",
      "     'left||none',\n",
      "     'left||right',\n",
      "     'left||through;right|right',\n",
      "     'left|||',\n",
      "     'left|||right',\n",
      "     'left|||slight_right;right',\n",
      "     'left||||right',\n",
      "     'merge_to_right|',\n",
      "     'none|merge_to_left',\n",
      "     'none|none|right',\n",
      "     'through',\n",
      "     'through|right',\n",
      "     'through|through',\n",
      "     'through||',\n",
      "     '|',\n",
      "     '|merge_to_left',\n",
      "     '|right',\n",
      "     '||',\n",
      "     '||merge_to_left',\n",
      "     '||right',\n",
      "     '|||right'])\n",
      "'placement:forward'\n",
      "set(['left_of:1'])\n",
      "'is_in'\n",
      "set(['Los Angeles, CA',\n",
      "     'Orange, CA',\n",
      "     'Orange,California,Calif.,CA,USA',\n",
      "     'San Luis Obispo, CA',\n",
      "     'USA, California',\n",
      "     'USA, California, Los Angeles County, Alhambra'])\n",
      "'building:height'\n",
      "set(['2.8'])\n",
      "'maxspeed:truck'\n",
      "set(['55 mph'])\n",
      "'tiger:AWATER'\n",
      "set(['0'])\n",
      "'created_by'\n",
      "set(['Merkaartor 0.13',\n",
      "     'Potlatch 0.10',\n",
      "     'Potlatch 0.10b',\n",
      "     'Potlatch 0.10c',\n",
      "     'Potlatch 0.10d',\n",
      "     'Potlatch 0.10e',\n",
      "     'Potlatch 0.10f',\n",
      "     'Potlatch 0.4c',\n",
      "     'Potlatch 0.5c',\n",
      "     'Potlatch 0.5d',\n",
      "     'Potlatch 0.7',\n",
      "     'Potlatch 0.8a',\n",
      "     'Potlatch 0.9a',\n",
      "     'Potlatch 0.9c'])\n",
      "'hov:minimum'\n",
      "set(['2', '3'])\n",
      "'name:full'\n",
      "set(['East Chevy Chase Drive', 'East Mountain Street'])\n",
      "'attribution'\n",
      "set(['CASIL CSP_Opbdys072008',\n",
      "     'Caltrans',\n",
      "     'Farmland Mapping and Monitoring Program',\n",
      "     'NHD',\n",
      "     'US Forest Service'])\n",
      "'tiger:county'\n",
      "set(['Los Angeles, CA',\n",
      "     'Los Angeles, CA:San Bernardino, CA',\n",
      "     'Los Angeles, CA; Orange, CA',\n",
      "     'Orange, CA',\n",
      "     'Orange, CA;Los Angeles, CA',\n",
      "     'Riverside, CA',\n",
      "     'San Bernardino',\n",
      "     'San Bernardino, CA',\n",
      "     'San Diego, CA',\n",
      "     'Ventura, CA',\n",
      "     'Ventura, CA;Los Angeles, CA'])\n",
      "'name:uk'\n",
      "set([u'\\u041e\\u043d\\u0442\\u0430\\u0440\\u0456\\u043e'])\n",
      "'motor_vehicle'\n",
      "set(['no', 'permissive', 'private', 'yes'])\n",
      "'faa'\n",
      "set(['CL54'])\n",
      "'railway:track_ref'\n",
      "set(['11', '735', '744'])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for key, value in types_values.items():                 #sample of keys and their different values\n",
    "    pprint.pprint(key), pprint.pprint(value) \n",
    "    if count == 20:\n",
    "        break    \n",
    "    count += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some of the tags for an element have address streets written as a whole as well as split up. I noticed that the source for most of this data was the Tiger GPS system.\n",
    "\n",
    "Some tags have addresses which give a direction as abrreviations such as N, S, E, W whereas other places have North, South, East, West.\n",
    "\n",
    "Some element tags have different notations for name keys. Some have the key as 'name' whereas others have 'name_1'.\n",
    "\n",
    "Phone numbers for different elements have different formats too. ('+1 xxx-xxx-xxxx', '1 xxx-xxx-xxxx', 'xxx xxx xxxx')\n",
    "\n",
    "Some elements have zipcode tags in their child tags, some have postcode tags. There are also zipcode_left and zipcode_right child tags for the same element \n",
    "\n",
    "One of the tags has an entire note ( under the key 'note') referring to inconsistencies.\n",
    "\n",
    "Mainly, and most importantly, street addresses have different forms too. Some have abbreviated forms like 'St', 'Rd' whereas others have 'Street', 'Road'.\n",
    "\n",
    "I will look into some of these tags in more depth and try to fix most of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to investigate the street addresses issue for the dataset. Looking through the data I noticed that street names were present in 'name', 'name_1' and 'addr:street' tags for way elements. For the node elements, street names are found in the 'addr:street' k values of the tag child elements. \n",
    "\n",
    "I decided to work with the values associated with the 'addr:street' keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_street(element):    #this will check if a key represents a street\n",
    "    return element.get('k') == 'addr:street'\n",
    "\n",
    "reg_exp = r'(?i)(\\b\\S+|\\d+(\\.?))$'   #This regular expressions will take a street name at return the last word.\n",
    "                                     #This is done to check with the common_street_types variable given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_street_types = ['Avenue', 'Boulevard', 'Court', 'Drive', 'Lane',\n",
    "                       'Parkway','Place', 'Road', 'Square', 'Street', 'Trail', 'Way']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_street(reg_ex, street_name):\n",
    "    match = re.search(reg_ex, street_name)\n",
    "    if match:\n",
    "        if match.group() not in common_street_types:\n",
    "            if match.group() not in street_corrections.keys():\n",
    "                return street_name\n",
    "            else:\n",
    "                return re.sub(reg_ex, street_corrections[match.group()], street_name)\n",
    "        else:\n",
    "            return street_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above takes a street name, checks if the last word of the street is a common street type. If not, it checks whether the last word is an abbreviated form as given in the street_corrections dictionary below. If it is, it corrects it accordingly and if not, just returns the street name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Varney St ----------> N Varney Street\n",
      "N Varney St ----------> N Varney Street\n",
      "Glenwood Road ----------> Glenwood Road\n",
      "Glenwood Road ----------> Glenwood Road\n",
      "Briercrest Avenue ----------> Briercrest Avenue\n",
      "Briercrest Avenue ----------> Briercrest Avenue\n",
      "Monte Vista Street ----------> Monte Vista Street\n",
      "Monte Vista Street ----------> Monte Vista Street\n",
      "Venice Boulevard ----------> Venice Boulevard\n",
      "Venice Boulevard ----------> Venice Boulevard\n",
      "Santa Anita Avenue ----------> Santa Anita Avenue\n",
      "Santa Anita Avenue ----------> Santa Anita Avenue\n",
      "Carlos Ave ----------> Carlos Avenue\n",
      "Carlos Ave ----------> Carlos Avenue\n",
      "Greystone Dr ----------> Greystone Drive\n",
      "Greystone Dr ----------> Greystone Drive\n",
      "San Gorgonio Dr ----------> San Gorgonio Drive\n",
      "San Gorgonio Dr ----------> San Gorgonio Drive\n",
      "Brookside Ave ----------> Brookside Avenue\n",
      "Brookside Ave ----------> Brookside Avenue\n"
     ]
    }
   ],
   "source": [
    "count = 0    #sample of correcting street names\n",
    "for event, elem in ET.iterparse(OSM_PATH, events = ('start',)):\n",
    "    if count == 20:\n",
    "        break\n",
    "    else:\n",
    "        if elem.tag =='tag' or elem.tag == 'node':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if is_street(tag):\n",
    "                    count += 1\n",
    "                    print tag.attrib['v'], '---------->',  get_street(reg_exp, tag.get('v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_corrections = {'St': 'Street',  'Rd': 'Road',\n",
    "                      'Wy' :'Way', 'Pkwy': 'Parkway', 'Pl': 'Place',\n",
    "                      'Ln': 'Lane', 'Dr': 'Drive', 'Ct' : 'Court',\n",
    "                      'Blvd.' : 'Boulevard', 'Blvd':'Boulevard', 'Blv.' : 'Boulevard', 'Ave':'Avenue',}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While skimming through the zipcodes, I noticed a bunch of values with more than just the standard 5 digits. So i decided to take these values and just return the first part of the zipcode which matched the conventional 5 digit format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_zip(elem):  #function that uses a regualr expression to check for zip/post code patterns in the key name\n",
    "    if re.search(r'(?i)(zip|:post)', elem.get('k')):\n",
    "        return elem.get('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_zip(elem):  #This function taks a zipcode and returns the first 5 digits of the zipcode\n",
    "    reg_ex_zip = r'(?P<zip>\\d{5})((\\S(\\s)?)(\\d+))*'      #regular expression to return the first 5 digits\n",
    "    return re.sub(reg_ex_zip, r'\\g<zip>', elem.get('v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90022:90640 ---------> 90022\n",
      "91730:91737 ---------> 91730\n",
      "90602:90605 ---------> 90602\n",
      "90602:90605 ---------> 90602\n",
      "92625:92651 ---------> 92625\n",
      "92625:92651 ---------> 92625\n",
      "90274:90717 ---------> 90274\n",
      "90274:90717 ---------> 90274\n",
      "90712:90807 ---------> 90712\n",
      "90712:90807 ---------> 90712\n"
     ]
    }
   ],
   "source": [
    "count = 0    #sample of how the zipcode cleaning returns values\n",
    "for event, elem in ET.iterparse(OSM_PATH, events = ('start',)):\n",
    "    if count == 10:\n",
    "        break\n",
    "    else:\n",
    "        if elem.tag =='node' or elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if is_zip(tag) and ':' in tag.get('v'):\n",
    "                    count += 1\n",
    "                    print tag.get('v'), '--------->', get_zip(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I looked at various phone numbers , I noticed that they had different formats and they are also under different key names. I decided to collect all the phone numbers and return them in a more standard +1 xxx-xxx-xxxx format. The function below does just that with the help of the regular expressions phone_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phone(elem):  #function to look through phone numbers\n",
    "    if elem.get('k') == 'phone' or elem.get('k') == 'fax':\n",
    "        return elem.get('v')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This regular expression finds all the values that resemble the pattern of a phone number with the area code in the U.S\n",
    "phone_re = r'(?P<area>\\d{3})(.+)?(?P<val2>\\d{3})(.+)?(?P<val3>\\d{4})'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_phone(elem):  ### This function takes in a phone number of a particular format and converts it to the standard format\n",
    "    numbers = get_phone(elem)\n",
    "    match = re.search(phone_re, numbers)\n",
    "    if match:\n",
    "            correct_numbers = re.sub(phone_re, r'+1 \\g<area>-\\g<val2>-\\g<val3>', match.group())\n",
    "            return correct_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 818 244 2113 ---------> +1 818-244-2113\n",
      "323-255-5416 ---------> +1 323-255-5416\n",
      "310 390-3454 ---------> +1 310-390-3454\n",
      "1-625- 574-1613 ---------> +1 625-574-1613\n",
      "+1 909 390 6788 ---------> +1 909-390-6788\n",
      "+1-805-684-9909 ---------> +1 805-684-9909\n",
      "+1-805-643-6615 ---------> +1 805-643-6615\n",
      "323-466-3251 ---------> +1 323-466-3251\n",
      "562-860-8454 ---------> +1 562-860-8454\n",
      "714-990-1400 ---------> +1 714-990-1400\n",
      "(714) 538-3764 ---------> +1 714-538-3764\n",
      "(213) 622-3333 ---------> +1 213-622-3333\n",
      "800-932-6278 ---------> +1 800-932-6278\n",
      "818-338-8888 ---------> +1 818-338-8888\n",
      "3104822035 ---------> +1 310-482-2035\n",
      "+1-213-403-3100 ---------> +1 213-403-3100\n",
      "+1-213-403-3000 ---------> +1 213-403-3000\n",
      "626-446-7238 ---------> +1 626-446-7238\n",
      "626-446-8222 ---------> +1 626-446-8222\n",
      "+1-310-656-8500 ---------> +1 310-656-8500\n"
     ]
    }
   ],
   "source": [
    "count = 0   #sample of phone number corrections\n",
    "for event, elem in ET.iterparse(OSM_PATH, events = ('start',)):\n",
    "    if count == 20:\n",
    "        break\n",
    "    else:\n",
    "        if elem.tag == 'node' or elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if get_phone(tag):\n",
    "                    count += 1\n",
    "                    print tag.get('v'), '--------->', correct_phone(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conversion makes the data look consistent and very clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I decided to look at street names that had abbreviations for their directions like E,W,N,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To fix abbreviations like N,S,E,W\n",
    "reg_e_dir = r'(?i)\\b[ewns]\\.?\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direction_dict = {'N' : 'North', 'E.': 'East', 'S': 'South', 'E': 'East'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_direction(regex, street_name):  #funtion that takes street names, looks for E, W, N, S and returns the full form.\n",
    "    match = re.search(regex, street_name)\n",
    "    if match:\n",
    "        if match.group() in direction_dict.keys():\n",
    "            return re.sub(regex, direction_dict[match.group()], street_name)\n",
    "        else:\n",
    "            return street_name\n",
    "    else:\n",
    "        return street_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at all the cleaning that was possible, it was time to collect the data from the osm file and put it into a csv format for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "before_colon = r'(?=(\\:)?)\\w+'  ### regular expression to find everything before the first colon \n",
    "after_colon = r'(?<=(\\:)).+'   ### regular expression to find everything after the first colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NODES_PATH = \"C:\\Users\\shawar\\Documents\\\\nodes.csv\"\n",
    "NODE_TAGS_PATH = \"C:\\Users\\shawar\\Documents\\\\nodes_tags.csv\"\n",
    "WAYS_PATH = \"C:\\Users\\shawar\\Documents\\\\ways.csv\"\n",
    "WAY_NODES_PATH = \"C:\\Users\\shawar\\Documents\\\\ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"C:\\Users\\shawar\\Documents\\\\ways_tags.csv\"\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\" \\?%#$@\\,\\.\\t\\r\\n]') ### regular expression to find non alphanumeric characters\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    \n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for node in NODE_FIELDS:\n",
    "            node_attribs[node] = element.attrib[node]  ### creating key-value pairs in the node_attribs dictionary \n",
    "                                                       ### where the keys are the elements in the NODE_FIELDS list \n",
    "                                                       ### and values are respective attributes\n",
    "            \n",
    "    \n",
    "        \n",
    "        for tag in element.iter('tag'):    ###iterating over each tag named 'tag'\n",
    "            diction = {}\n",
    "            if not re.search(problemchars, tag.get('k')):    ### if characters in the problemchars regular expression are not\n",
    "                                                             ### in the tag keys, assign it to 'id' in diction\n",
    "                diction['id'] = element.get('id') \n",
    "                ### keys of tags have to be treated differently based on whether there is a ':' or not. The following if \n",
    "                ### statement is to deal with that.\n",
    "                \n",
    "                if ':' in tag.get('k'):                      \n",
    "                    if is_zip(tag):                          ### calling this function to check if it is a zipcode\n",
    "                        diction['value'] = get_zip(tag)      ### calling this function to extract the zipcode value and assign\n",
    "                                                             ### it to the 'value' key in diction\n",
    "                            \n",
    "                        ### the following two steps extracts everything before and after the first colon in the key tag \n",
    "                        ###and assigns it to the 'type' key and 'key' key of diction\n",
    "                        \n",
    "                        diction['type'] = re.search(before_colon, tag.get('k')).group()\n",
    "                        diction['key'] = re.search(after_colon,tag.get('k')).group()\n",
    "                    \n",
    "                    elif is_street(tag):   ### to check if the value tag contains a street name\n",
    "                        right_street = get_street(reg_exp, tag.get('v'))  ### calls function to change the street name to the \n",
    "                                                                          ### corrected format using regular expression \n",
    "                                                                          ### explained above\n",
    "                            \n",
    "                        diction['value'] = get_direction(reg_e_dir, right_street) ### Changing directional abbreviations \n",
    "                                                                                  ### to their full form using regular \n",
    "                                                                                  ### expression explained above\n",
    "                            \n",
    "                        diction['key'] = re.search(before_colon, tag.get('k')).group()\n",
    "                        diction['type'] = re.search(after_colon, tag.get('k')).group()\n",
    "                    else:\n",
    "                        diction['key'] = tag.get('k')\n",
    "                        diction['value'] = tag.get('v')\n",
    "                        diction['type'] = re.search(before_colon, tag.get('k')).group()\n",
    "                        \n",
    "                else:  ###if no ':' in the key\n",
    "                    \n",
    "                    if get_phone(tag):  ###function to check if tag resembles a phone number\n",
    "                        diction['value'] = correct_phone(tag) ### function that returns the phone number in the \n",
    "                                                              ### correct phone number\n",
    "                            \n",
    "                        diction['type'] = 'regular' ### if no ':', the rule was to return 'regular' as the type\n",
    "                        diction['key'] = tag.get('k')\n",
    "                    else:\n",
    "                        diction['value'] = tag.get('v')\n",
    "                        diction['type'] = 'regular'\n",
    "                        diction['key'] = tag.get('k')\n",
    "                        \n",
    "                tags.append(diction)   ###appending the dictionary to 'tags' list\n",
    "        return {'node': node_attribs, 'node_tags': tags}            \n",
    "     \n",
    "    if element.tag == 'way':\n",
    "        for way in WAY_FIELDS:\n",
    "            way_attribs[way] = element.attrib[way]  ### similar process to nodes above\n",
    "            \n",
    "            \n",
    "        \n",
    "        count = 0\n",
    "        for tag in element.iter('nd'):\n",
    "            way_nd = {}\n",
    "            way_nd['id'] = element.get('id')\n",
    "            way_nd['node_id'] = tag.get('ref')\n",
    "            way_nd['position'] = count  ### each node of a particular way is given an ordered number from \n",
    "                                        ### 0 - n number of nodes\n",
    "            way_nodes.append(way_nd)\n",
    "            count += 1\n",
    "        \n",
    "        \n",
    "        for tag in element.iter('tag'): ### looping through the 'tag' tags of each way element in the same process as the nodes\n",
    "            diction = {}\n",
    "            if not re.search(problemchars, tag.get('k')):\n",
    "                diction['id'] = element.get('id')\n",
    "                if ':' in tag.get('k'):\n",
    "                    if is_zip(tag):\n",
    "                        diction['value'] = get_zip(tag)\n",
    "                        diction['type'] = re.search(before_colon, tag.get('k')).group()\n",
    "                        diction['key']  = re.search(after_colon, tag.get('k')).group()\n",
    "                    elif is_street(tag):\n",
    "                        right_street = get_street(reg_exp, tag.get('v'))\n",
    "                        diction['value'] = get_direction(reg_e_dir, right_street)\n",
    "                        diction['key'] = re.search(before_colon, tag.get('k')).group()\n",
    "                        diction['type'] = re.search(after_colon, tag.get('k')).group()\n",
    "                    else:\n",
    "                        diction['key'] = tag.get('k')\n",
    "                        diction['value'] = tag.get('v')\n",
    "                        diction['type'] = re.search(before_colon, tag.get('k')).group()\n",
    "                else:\n",
    "                    if get_phone(tag):\n",
    "                        diction['value'] = correct_phone(tag)\n",
    "                        diction['type'] = 'regular'\n",
    "                        diction['key'] = tag.get('k')\n",
    "                    else:\n",
    "                        diction['value'] = tag.get('v')\n",
    "                        diction['type'] = 'regular'\n",
    "                        diction['key'] = tag.get('k')\n",
    "                tags.append(diction)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_map(OSM_PATH, validate=False)\n",
    "    print \"Done\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Sizes:\n",
    "\n",
    ".osm File --> 158 MB                                                                                                     \n",
    ".db File --> 238 MB                                                                                                        \n",
    "nodes.csv --> 64.MB                                                                                                         \n",
    "nodes_tags.csv --> 739 KB                                                                                                    \n",
    "ways.csv --> 4.58 MB                                                                                                         \n",
    "ways_nodes.csv --> 19.2 MB                                                                                                  \n",
    "ways_tags.csv --> 16.4MB                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing everything to sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Total number of nodes\n",
    "\n",
    "    sqlite> SELECT count(*) FROM nodes;                 \n",
    "714852\n",
    "\n",
    "#Total number of ways\n",
    "\n",
    "    sqlite> SELECT count(*) FROM ways;\n",
    "69756\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Number of Unique IDs\n",
    "\n",
    "    sqlite> SELECT count(DISTINCT(uid)) FROM(SELECT uid FROM nodes UNION ALL SELECT uid FROM ways);\n",
    "1734\n",
    "\n",
    "#Top 5 Contributors\n",
    "\n",
    "    sqlite> SELECT user, count(user) as Contributions                                                                           \n",
    "   ...> FROM (SELECT user FROM nodes UNION ALL SELECT user from ways)                                                         \n",
    "   ...> GROUP BY user                                                                                                       \n",
    "   ...> ORDER BY Contributions DESC                                                                                         \n",
    "   ...> LIMIT 5;                                                                                                              \n",
    "   \n",
    "manings_labuildings|55706                                                                                                \n",
    "calfarome_labuilding|53499                                                                                                      \n",
    "Luis36995_labuildings|49100                                                                                                     \n",
    "dannykath_labuildings|43463                                                                                                  \n",
    "schleuss_imports|43115                                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#calculating average contributions from users\n",
    "\n",
    "      sqlite> SELECT avg(num) FROM (SELECT COUNT(*) as num\n",
    "  ...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) nw                                                         \n",
    "  ...> GROUP BY nw.user);                                                                                                     \n",
    "452.223631123919\n",
    "\n",
    "\n",
    "\n",
    "Now let us compare the average contributions of the top 100 contributors vs the rest\n",
    "\n",
    "TOP 100 Average                                                                                                           \n",
    "      sqlite> SELECT avg(num) FROM (SELECT COUNT(*) as num\n",
    "   ...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) nw                                                      \n",
    "   ...> GROUP BY nw.user ORDER BY num DESC LIMIT 100);                                                                        \n",
    "7412.65\n",
    "\n",
    "100- 1734 Average                                                                                                        \n",
    "      sqlite> SELECT avg(num) FROM (SELECT COUNT(*) as num                                                                     \n",
    "       ...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) nw                                                     \n",
    "       ...> GROUP BY nw.user ORDER BY num DESC LIMIT 100,1634);                                                                                                                                 \n",
    "26.5250917992656\n",
    "\n",
    "\n",
    "As we can see, the top contributors contribute much more than the rest. Infact, if you go a little deeper, and see the bottom 1000 people:-\n",
    "\n",
    "    sqlite> SELECT sum(num) FROM (SELECT COUNT(*) as num                                                                       \n",
    "   ...> FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) nm                                                      \n",
    "   ...> GROUP BY nm.user ORDER BY num DESC LIMIT 734,1000);\n",
    "   \n",
    "1970\n",
    "\n",
    "The bottom 1000 people contributions are not even remotely close to the top contributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#No of Subway Restaurants\n",
    "\n",
    "    sqlite> SELECT count(*) FROM nodes_tags                                                                            \n",
    "    WHERE value ='Subway';\n",
    "4\n",
    "\n",
    "\n",
    "#Top 10 Number of amenities\n",
    "\n",
    "    sqlite> SELECT value, count(value) as Total FROM\n",
    "   ...> (SELECT value FROM nodes_tags where key = 'amenity'                                                                     \n",
    "   ...> UNION ALL SELECT value FROM ways_tags where key ='amenity')                                                             \n",
    "   ...> GROUP BY value ORDER BY Total DESC                                                                                         \n",
    "   ...> LIMIT 10;                                                                                                        \n",
    "   \n",
    "parking|247                                                                                                                     \n",
    "school|95                                                                                                                       \n",
    "place_of_worship|88                                                                                                             \n",
    "restaurant|62                                                                                                                  \n",
    "fast_food|47                                                                                                                 \n",
    "fuel|25                                                                                                                        \n",
    "toilets|25                                                                                                                     \n",
    "cafe|23                                                                                                                         \n",
    "bench|19                                                                                                                        \n",
    "fire_station|15                                                                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Number of Cycle Lanes\n",
    "\n",
    "    sqlite> SELECT value, count(*) FROM ways_tags\n",
    "   ...> WHERE value ='cycleway';  \n",
    "   \n",
    "cycleway|34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for improving OSM:\n",
    "\n",
    "  An issue I came across while wrangling this data were the inconsistencies to explain the same type of data. One of the reasons for this is that the data is coming from different sources, for example 'tiger GPS system'. During the analysis, I noticed that zipcodes were given in a 'zipcode-right' and 'zipcode-left' format for the same way tag. Both these values were always equal. A great way to counter this and make sure that the data coming from different sources is always in a consistent format is to allow edits to made in a structured input format (Name, Street, Type, zipcode).\n",
    "  \n",
    "  Another curious thing I noticed was that some of the way tags for an element had the complete street address whereas in some elements, there were separate tags dividing the address. \n",
    "  \n",
    "  Finally, most contributions are from a handful of users where even the bottom 1000 were far short in terms of contributions when compared to the top contributor. The top 5 contributors had contributions way above 40000, but the average contributions for the top 100 was only around 7500. The average contributions drop even further for the contributors out of the top 100 (26). Thus, we see that, where people at the top contribute in the tens of thousands, people below are hardly contributing 50. The total number of contributions of the bottom thousand is 1970, which when compared with the highest contributor (55706), shows us how much of a gap there really is in terms of contributions.\n",
    "  \n",
    "  Contributions need to come from more users in order to improve the data quality. One way of doing this would be to create incentives for people with low number of contributions to contribute. Another way would be to create a competitive edge by implementing a scoring system among users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCES:\n",
    "\n",
    "1) Openstreetmap link - https://mapzen.com/data/metro-extracts/metro/los-angeles_california/                                \n",
    "2) udacity.com                                                                                                          \n",
    "3) stackoverflow.com                                                                                                         \n",
    "4) https://wiki.openstreetmap.org/                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
